{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
    "import numpy as np\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime prove fastText\n",
    "il modello creato Ã¨ stato creato con 1 epoca dal modello wikipedia, da migliorare e diminuire le parole, \n",
    "introducendo un dizionario di paroli comuni italiane (vedi come fa il professore)\n",
    "\n",
    "le funzioni seguenti servono per fare lo spell checker e non per predirre la parola sucessiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-02 19:31:58,763 : INFO : loading Word2Vec object from WikiW2C1.model\n",
      "2020-04-02 19:31:59,276 : INFO : loading wv recursively from WikiW2C1.model.wv.* with mmap=None\n",
      "2020-04-02 19:31:59,277 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-04-02 19:31:59,277 : INFO : loading vocabulary recursively from WikiW2C1.model.vocabulary.* with mmap=None\n",
      "2020-04-02 19:31:59,278 : INFO : loading trainables recursively from WikiW2C1.model.trainables.* with mmap=None\n",
      "2020-04-02 19:31:59,278 : INFO : setting ignored attribute cum_table to None\n",
      "2020-04-02 19:31:59,279 : INFO : loaded WikiW2C1.model\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('WikiW2C1.model') #modello creato con fast text 1 epoca (da migliorare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/stefanoraimondousai/Documents/ReadingCourse/text_pulito.txt' #testo con chat marta\n",
    "sentences = datapath(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-02 19:32:03,572 : INFO : training model with 8 workers on 63937 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-02 19:32:03,579 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-02 19:32:03,579 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-02 19:32:03,579 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-02 19:32:03,580 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-02 19:32:03,580 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-02 19:32:03,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-02 19:32:03,581 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-02 19:32:03,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-02 19:32:03,583 : INFO : EPOCH - 1 : training on 66 raw words (45 effective words) took 0.0s, 7121 effective words/s\n",
      "2020-04-02 19:32:03,583 : WARNING : EPOCH - 1 : supplied example count (66) did not equal expected count (11036232)\n",
      "2020-04-02 19:32:03,588 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-02 19:32:03,589 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-02 19:32:03,590 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-02 19:32:03,590 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-02 19:32:03,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-02 19:32:03,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-02 19:32:03,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-02 19:32:03,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-02 19:32:03,594 : INFO : EPOCH - 2 : training on 66 raw words (50 effective words) took 0.0s, 9410 effective words/s\n",
      "2020-04-02 19:32:03,594 : WARNING : EPOCH - 2 : supplied example count (66) did not equal expected count (11036232)\n",
      "2020-04-02 19:32:03,604 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-02 19:32:03,605 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-02 19:32:03,605 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-02 19:32:03,606 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-02 19:32:03,606 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-02 19:32:03,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-02 19:32:03,608 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-02 19:32:03,608 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-02 19:32:03,609 : INFO : EPOCH - 3 : training on 66 raw words (46 effective words) took 0.0s, 8765 effective words/s\n",
      "2020-04-02 19:32:03,609 : WARNING : EPOCH - 3 : supplied example count (66) did not equal expected count (11036232)\n",
      "2020-04-02 19:32:03,615 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-02 19:32:03,616 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-02 19:32:03,617 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-02 19:32:03,618 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-02 19:32:03,618 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-02 19:32:03,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-02 19:32:03,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-02 19:32:03,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-02 19:32:03,621 : INFO : EPOCH - 4 : training on 66 raw words (44 effective words) took 0.0s, 7412 effective words/s\n",
      "2020-04-02 19:32:03,621 : WARNING : EPOCH - 4 : supplied example count (66) did not equal expected count (11036232)\n",
      "2020-04-02 19:32:03,627 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-04-02 19:32:03,628 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-04-02 19:32:03,628 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-04-02 19:32:03,629 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-04-02 19:32:03,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-02 19:32:03,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-02 19:32:03,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-02 19:32:03,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-02 19:32:03,632 : INFO : EPOCH - 5 : training on 66 raw words (45 effective words) took 0.0s, 8801 effective words/s\n",
      "2020-04-02 19:32:03,633 : WARNING : EPOCH - 5 : supplied example count (66) did not equal expected count (11036232)\n",
      "2020-04-02 19:32:03,634 : INFO : training on a 330 raw words (230 effective words) took 0.1s, 3793 effective words/s\n",
      "2020-04-02 19:32:03,634 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(230, 330)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences,epochs=5,total_examples=model.corpus_count, compute_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = list(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict_output_word(model, context_words_list, topn=10):\n",
    "        from numpy import exp, dot, zeros, random, dtype, float32 as REAL,\\\n",
    "        uint32, seterr, array, uint8, vstack, fromstring, sqrt,\\\n",
    "        empty, sum as np_sum, ones, logaddexp, log, outer\n",
    "        from scipy.special import expit\n",
    "        from gensim import utils, matutils  # utility fnc for pickling, common scipy operations etc\n",
    "\n",
    "        if not model.negative:\n",
    "            raise RuntimeError(\n",
    "                \"We have currently only implemented predict_output_word for the negative sampling scheme, \"\n",
    "                \"so you need to have run word2vec with negative > 0 for this to work.\"\n",
    "            )\n",
    "\n",
    "        if not hasattr(model.wv, 'vectors') or not hasattr(model.trainables, 'syn1neg'):\n",
    "            raise RuntimeError(\"Parameters required for predicting the output words not found.\")\n",
    "\n",
    "        word_vocabs = [model.wv.vocab[w] for w in context_words_list if w in model.wv.vocab]\n",
    "        if not word_vocabs:\n",
    "            warnings.warn(\"All the input context words are out-of-vocabulary for the current model.\")\n",
    "            return None\n",
    "\n",
    "        word2_indices = [word.index for word in word_vocabs]\n",
    "\n",
    "        l1 = np_sum(model.wv.vectors[word2_indices], axis=0)\n",
    "        if word2_indices and model.cbow_mean:\n",
    "            l1 /= len(word2_indices)\n",
    "\n",
    "        # propagate hidden -> output and take softmax to get probabilities\n",
    "        prob_values = exp(dot(l1, model.trainables.syn1neg.T))\n",
    "        prob_values /= sum(prob_values)\n",
    "        top_indices = matutils.argsort(prob_values, topn=topn, reverse=True)\n",
    "        # returning the most probable output words with their probabilities\n",
    "        return [(model.wv.index2word[index1], prob_values[index1]) for index1 in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(word, similar_word, similarity, constant = 0.5, min_weight=3):\n",
    "    min_similarity = similarity > constant   \n",
    "    word_len = 1 if len(word) <= 4 else 2 #se Ã¨ minore di 4 Ã¨ un articolo quasi sicuramente\n",
    "    exist = 1 if word in dictionary else 0 # esiste nel dizionario?\n",
    "    min_len = len(similar_word) > 4 #se Ã¨ piÃ¹ lungo di 4 evito che siano articoli\n",
    "    check_first_word = 1 if word[0] == similar_word[0] else 0 #controllo la prima lettera della parola\n",
    "    levenshtein_distance = nltk.edit_distance(word, similar_word) <= word_len #sostituire con quello di marta\n",
    "    weight = word_len + min_similarity + min_len + exist + levenshtein_distance\n",
    "    if weight > min_weight:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellChecker(word):\n",
    "    most_similar = model.wv.most_similar(word, topn=50) #parole simili dal modello\n",
    "    result = list(filter(lambda x: weight(word, x[0], x[1]), most_similar))#filtro con la funzione weight\n",
    "    result = {'prediction': result[:3]} #dizionario con le prime 5 parole\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-02 19:32:12,523 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'prpfessore' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bbd99777e457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspellChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prpfessore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-df74076bac29>\u001b[0m in \u001b[0;36mspellChecker\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspellChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmost_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#parole simili dal modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#filtro con la funzione weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#dizionario con le prime 5 parole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'prpfessore' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "spellChecker('prpfessore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maresciallo', 0.0025712752),\n",
       " ('maciel', 0.0022833087),\n",
       " ('generale', 0.0020807434),\n",
       " ('marco', 0.0019856805),\n",
       " ('ore', 0.0019567062),\n",
       " ('vangelo', 0.0018323088),\n",
       " ('napoleone', 0.0015985918),\n",
       " ('ottobre', 0.001584941),\n",
       " ('00', 0.0014943439),\n",
       " ('gesÃ¹', 0.0014279209),\n",
       " ('mattino', 0.0011107996),\n",
       " ('alle', 0.00086087454),\n",
       " ('soldati', 0.0008585797),\n",
       " ('ordine', 0.0008323802),\n",
       " ('verso', 0.0007936085),\n",
       " ('profeta', 0.00075703964),\n",
       " ('14', 0.00074982725),\n",
       " ('pomeriggio', 0.00057773816),\n",
       " ('truppe', 0.0005752581),\n",
       " ('versetto', 0.00056621875),\n",
       " ('fianco', 0.000548455),\n",
       " ('momento', 0.0005382026),\n",
       " ('moro', 0.00050576596),\n",
       " ('mosÃ¨', 0.0005003582),\n",
       " ('armata', 0.00049785496),\n",
       " ('principe', 0.0004932077),\n",
       " ('lunedÃ¬', 0.0004915489),\n",
       " ('102', 0.00046582235),\n",
       " ('000', 0.00045566593),\n",
       " ('capodanno', 0.00045552698),\n",
       " ('mentre', 0.0004422876),\n",
       " ('voi', 0.00044033604),\n",
       " ('voto', 0.00042722374),\n",
       " ('corpo', 0.00042338882),\n",
       " ('radio', 0.00041576417),\n",
       " ('battaglia', 0.0004143782),\n",
       " ('13', 0.00040211857),\n",
       " ('30', 0.0003959282),\n",
       " ('horowitz', 0.00039243337),\n",
       " ('rogo', 0.00038594595),\n",
       " ('venerdÃ¬', 0.00038065665),\n",
       " ('quindi', 0.0003798769),\n",
       " ('fuoco', 0.00037701518),\n",
       " ('rtl', 0.00037671404),\n",
       " ('giorno', 0.00036819727),\n",
       " ('joni', 0.00036670486),\n",
       " ('seveso', 0.00035754143),\n",
       " ('16', 0.0003563787),\n",
       " ('imperatore', 0.0003538223),\n",
       " ('avanti', 0.00034789994)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_output_word(model, ['giovedÃ¬', 'andiamo', 'al'], topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
