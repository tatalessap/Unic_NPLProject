{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "import gensim\n",
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models import Phrases, TfidfModel\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.test.utils import datapath \n",
    "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
    "import logging\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"file.txt\", \"r\") as f1:\n",
    "         data=str(f1.readlines())\n",
    "         sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['organo a pompa\\\\n', 'l\\\\'organo a pompa è un tipo di organo a serbatoio d\\\\'aria costituito da una (o\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('WikiItaliaGennaio2019.txt') as fin, open('WikiPulito.txt','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens=nltk.regexp_tokenize(line, r\"\\w+\")\n",
    "        print(' '.join(tokens), end='\\n', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n",
    "logging.root.setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string =''  \n",
    "with open('wiki_slim.txt', 'r') as file:\n",
    "    string = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ''.join([c for c in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organo',\n",
       " 'a',\n",
       " 'pompa',\n",
       " 'l',\n",
       " \"'\",\n",
       " 'organo',\n",
       " 'a',\n",
       " 'pompa',\n",
       " 'è',\n",
       " 'un',\n",
       " 'tipo',\n",
       " 'di',\n",
       " 'organo',\n",
       " 'a',\n",
       " 'serbatoio',\n",
       " 'd',\n",
       " \"'\",\n",
       " 'aria',\n",
       " 'costituito',\n",
       " 'da',\n",
       " 'una',\n",
       " '(',\n",
       " 'o',\n",
       " 'più',\n",
       " ')',\n",
       " 'tas']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.wordpunct_tokenize(string[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"[()!@#$:).;,?&-<>\\n]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organo',\n",
       " 'a',\n",
       " 'pompa',\n",
       " 'l',\n",
       " 'organo',\n",
       " 'a',\n",
       " 'pompa',\n",
       " 'è',\n",
       " 'un',\n",
       " 'tipo',\n",
       " 'di',\n",
       " 'organo',\n",
       " 'a',\n",
       " 'serbatoio',\n",
       " 'd',\n",
       " 'aria',\n",
       " 'costituito',\n",
       " 'da',\n",
       " 'una',\n",
       " 'o',\n",
       " 'più',\n",
       " 'tas']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(string[0:100], r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string=re.sub(r\"[()'!@#$:).;,?&-<>\\n]\", \" \", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram=Phrases(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraser = Phraser(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = Phrases(phraser[sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraser=Phraser(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(phraser[sentences], \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=300,      # Dimensionality of word embeddings\n",
    "                 workers=4,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=5,\n",
    "                 sg=1)        # Number of epochs training over corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('WikiModelItaSlim.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del string\n",
    "del sentences\n",
    "del ngram\n",
    "del phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanoraimondousai/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('una', 0.8480138778686523),\n",
       " ('da', 0.8467680215835571),\n",
       " ('ma', 0.8465350866317749),\n",
       " ('un', 0.8465103507041931),\n",
       " ('di', 0.845416247844696),\n",
       " ('dalla', 0.8450683355331421),\n",
       " ('ad', 0.8450096845626831),\n",
       " ('il', 0.8449968099594116),\n",
       " ('e', 0.8447810411453247),\n",
       " ('quando', 0.8443877696990967)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('grande')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('astronomia', 3.8125734e-06),\n",
       " ('architettura', 3.8048383e-06),\n",
       " ('stelle', 3.747457e-06),\n",
       " ('sole', 3.7394166e-06),\n",
       " ('galassie', 3.7333605e-06),\n",
       " ('oggetti', 3.7309885e-06),\n",
       " ('via_lattea', 3.7240495e-06),\n",
       " ('lo_studio', 3.7203274e-06),\n",
       " ('antropologia', 3.7176717e-06),\n",
       " ('dell_universo', 3.7141992e-06)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word([\"l'italia\",'è','la','capitale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
